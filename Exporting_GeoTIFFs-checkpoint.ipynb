{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Cloud-Optimised GeoTIFFs\n",
    "\n",
    "* **Products used:** \n",
    "[ s2_l2a](https://explorer.digitalearth.africa/s2_l2a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Keywords** :index:`data used; sentinel-2`, :index:`data methods; exporting`, :index:`data format; GeoTIFF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "At the end of an analysis it can be useful to export data to a GeoTIFF file (e.g. `outputname.tif`), either to save results or to allow for exploring results in a GIS software platform (e.g. ArcGIS or QGIS).\n",
    "\n",
    "A `Cloud Optimized GeoTIFF (COG)` is a regular GeoTIFF file, aimed at being hosted on a HTTP file server, with an internal organization that enables more efficient workflows on the cloud. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook shows a number of ways to export a GeoTIFF file:\n",
    "\n",
    "1. Exporting a single-band, single time-slice GeoTIFF from an xarray object loaded through a `dc.load` query\n",
    "2. Exporting a multi-band, single time-slice GeoTIFF from an xarray object loaded through a `dc.load` query\n",
    "3. Exporting multiple GeoTIFFs, one for each time-slice of an xarray object loaded through a `dc.load` query\n",
    "4. Exporting data from lazily loaded `dask arrays`\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deafrica_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatacube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m write_cog\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatacube\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Geometry\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeafrica_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatahandling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_ard\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeafrica_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rgb\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeafrica_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mareaofinterest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m define_area\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deafrica_tools'"
     ]
    }
   ],
   "source": [
    "\n",
    "import datacube\n",
    "import geopandas as gpd\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import Geometry\n",
    "\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import rgb\n",
    "from deafrica_tools.areaofinterest import define_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='Exporting_GeoTIFFs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sentinel-2 data from the datacube\n",
    "\n",
    "Here we are loading in a timeseries of Sentinel-2 satellite images through the datacube API.\n",
    "This will provide us with some data to work with.\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis over.\n",
    "The parameters are\n",
    "\n",
    "* `lat`: The central latitude to analyse (e.g. `6.502`).\n",
    "* `lon`: The central longitude to analyse (e.g. `-1.409`).\n",
    "* `buffer`: The number of square degrees to load around the central latitude and longitude.\n",
    "For reasonable loading times, set this as `0.1` or lower.\n",
    "\n",
    "\n",
    "#### Select location\n",
    "To define the area of interest, there are two methods available:\n",
    "\n",
    "1. By specifying the latitude, longitude, and buffer. This method requires you to input the central latitude, central longitude, and the buffer value in square degrees around the center point you want to analyze. For example, `lat = 10.338`, `lon = -1.055`, and `buffer = 0.1` will select an area with a radius of 0.1 square degrees around the point with coordinates (10.338, -1.055).\n",
    "\n",
    "2. By uploading a polygon as a `GeoJSON or Esri Shapefile`. If you choose this option, you will need to upload the geojson or ESRI shapefile into the Sandbox using Upload Files button <img align=\"top\" src=\"../Supplementary_data/upload_files_icon.png\"> in the top left corner of the Jupyter Notebook interface. ESRI shapefiles must be uploaded with all the related files `(.cpg, .dbf, .shp, .shx)`. Once uploaded, you can use the shapefile or geojson to define the area of interest. Remember to update the code to call the file you have uploaded.\n",
    "\n",
    "To use one of these methods, you can uncomment the relevant line of code and comment out the other one. To comment out a line, add the `\"#\"` symbol before the code you want to comment out. By default, the first option which defines the location using latitude, longitude, and buffer is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_area' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set the area of interest\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Method 1: Specify the latitude, longitude, and buffer of kilifi\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m aoi \u001b[38;5;241m=\u001b[39m \u001b[43mdefine_area\u001b[49m(lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.63045\u001b[39m, lon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m39.84992\u001b[39m, buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Method 2: Use a polygon as a GeoJSON or Esri Shapefile. \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# aoi = define_area(vector_path='aoi.shp')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Create a geopolygon and geodataframe of the area of interest\u001b[39;00m\n\u001b[0;32m     10\u001b[0m geopolygon \u001b[38;5;241m=\u001b[39m Geometry(aoi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m], crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsg:4326\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'define_area' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the area of interest\n",
    "\n",
    "# Method 1: Specify the latitude, longitude, and buffer of kilifi\n",
    "aoi = define_area(lat=-3.63045, lon=39.84992, buffer=0.1)\n",
    "\n",
    "# Method 2: Use a polygon as a GeoJSON or Esri Shapefile. \n",
    "# aoi = define_area(vector_path='aoi.shp')\n",
    "\n",
    "#Create a geopolygon and geodataframe of the area of interest\n",
    "geopolygon = Geometry(aoi[\"features\"][0][\"geometry\"], crs=\"epsg:4326\")\n",
    "geopolygon_gdf = gpd.GeoDataFrame(geometry=[geopolygon], crs=geopolygon.crs)\n",
    "\n",
    "# Get the latitude and longitude range of the geopolygon\n",
    "lat_range = (geopolygon_gdf.total_bounds[1], geopolygon_gdf.total_bounds[3])\n",
    "lon_range = (geopolygon_gdf.total_bounds[0], geopolygon_gdf.total_bounds[2])\n",
    "\n",
    "# Create a reusable query\n",
    "query = {\n",
    "    'x': lon_range,\n",
    "    'y': lat_range,\n",
    "    'time': ('2018-01-01', '2024-01-01'),\n",
    "    'resolution': (-20, 20),\n",
    "    'measurements': ['red', 'green', 'blue'],\n",
    "    'output_crs':'EPSG:6933'\n",
    "}\n",
    "\n",
    "# Load available data from Landsat 8 and filter to retain only times\n",
    "# with at least 50% good data\n",
    "ds = load_ard(dc=dc, \n",
    "              products=['s2_l2a'], \n",
    "              **query)\n",
    "\n",
    "# Print output data\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot an rgb image to confirm we have data\n",
    "\n",
    "The white regions are cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(ds, index=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a single-band, single time-slice GeoTIFF\n",
    "\n",
    "This method uses the `datacube.utils.cog` function [write_cog](https://datacube-core.readthedocs.io/en/latest/api/utilities/generate/datacube.utils.cog.write_cog.html), where cog stands for [Cloud-Optimised-Geotiff](https://www.cogeo.org/) to export a simple single-band, single time-slice COG. \n",
    "\n",
    "A few important caveats should be noted when using this function:\n",
    "1. It requires an `xarray.DataArray`; supplying an `xarray.Dataset` will return an error. To convert a `xarray.Dataset` to an array run the following: \n",
    "\n",
    "        da = ds.to_array()\n",
    "\n",
    "2. This function generates a temporary in-memory tiff file without compression.  This means the function will use about 1.5 to 2 times the memory required using the depreciated `datacube.helper.write_geotiff`.\n",
    "\n",
    "3. If you pass a `dask array` into the function, `write_cog` will not output a geotiff, but will instead return a` Dask Delayed` object. To trigger the output of the geotiff run `.compute()` on the dask delayed object: \n",
    "\n",
    "        write_cog(ds.red.isel(time=0), \"red.tif\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single time-slice and a single band from the dataset.\n",
    "singleBandtiff = ds.red.isel(time=5)\n",
    "\n",
    "# Write GeoTIFF to a location\n",
    "write_cog(singleBandtiff,\n",
    "          fname=\"red_band.tif\",\n",
    "          overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a multi-band, single time-slice GeoTIFF\n",
    "\n",
    "Here we select a single time and export all the bands in the dataset using the `datacube.utils.cog.write_cog` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single time-slice\n",
    "rgb_tiff = ds.isel(time=5).to_array()\n",
    "\n",
    "# Write multi-band GeoTIFF to a location\n",
    "write_cog(rgb_tiff,\n",
    "          fname='rgb.tif',\n",
    "          overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export multiple GeoTIFFs, one for each time-slice of an xarray\n",
    "\n",
    "If we want to export all of the time steps in a dataset as a GeoTIFF, we can wrap our `write_cog` function in a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds.time)):\n",
    "\n",
    "    # We will use the date of the satellite image to name the GeoTIFF\n",
    "    date = ds.isel(time=i).time.dt.strftime('%Y-%m-%d').data\n",
    "    print(f'Writing {date}')\n",
    "    \n",
    "    # Convert current time step into a `xarray.DataArray`\n",
    "    singleTimestamp = ds.isel(time=i).to_array()\n",
    "\n",
    "    # Write GeoTIFF  \n",
    "    write_cog(singleTimestamp,\n",
    "              fname=f'{date}.tif',\n",
    "              overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting GeoTIFFs from a dask array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a lazily-loaded dask array into the function, `write_cog` will not immediately output a GeoTIFF, but will instead return a `dask.delayed` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazily load data using dask\n",
    "ds_dask = dc.load(product='s2_l2a', \n",
    "                  dask_chunks={},\n",
    "                  **query)\n",
    "\n",
    "# Run `write_cog`\n",
    "ds_delayed = write_cog(geo_im=ds_dask.isel(time=5).to_array(), \n",
    "                       fname='dask_geotiff.tif',\n",
    "                       overwrite=True)\n",
    "\n",
    "# Print dask.delayed object\n",
    "print(ds_delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trigger the GeoTIFF to be exported to file, run `.compute()` on the `dask.delayed` object. The file will now appear in the file browser to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_delayed.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
